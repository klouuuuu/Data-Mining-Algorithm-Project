#判定属于鱼类还是鱼类项目
'''
构造一个决策树:使用 createBranch() 方法，如下所示:
def createBranch():
    检测数据集中的所有数据的分类标签是否相同:
        If so return 类标签
        Else:
            寻找划分数据集的最好特征（划分之后信息熵最小，也就是信息增益最大的特征）
            划分数据集
            创建分支节点
                for 每个划分的子集
                    调用函数 createBranch （创建分支的函数）并增加返回结果到分支节点中
            return 分支节点
'''   



#收集数据、输入数据
def creatDataSet():
    dataSet=[[1, 1, 'yes'],
            [1, 1, 'yes'],
            [1, 0, 'no'],
            [0, 1, 'no'],
            [0, 1, 'no']]
    labels=['no surfacing', 'flippers']
    return dataSet,labels
    
   
#计算熵的函数
def calcShannonEnt(dataSet):
    #表示数据量
    length=len(dataSet)
    #计算不同标签出现次数
    labelnum={}
    for line in dataSet:
        nowlabel=line[-1]
        if (labelnum[nowlabel] not in labelnum.key()): 
            labelnum[nowlabel]=0
        labelnum[nowlabel]+=1
    #求出香农熵
    ShannonEnt=0.0
    for key in labelnum:
        prob=float(labelnum[key]/length)
        ShannonEnt-=prob*log(prob,2)
    return ShannonEnt
    

#根据给定特征划分数据集
def splitDataSet(dataSet,index,value):
    """
    参数：原数据集，给定特征，给定特征的值（eg.yes）
    返回值：index列为value的数据集【该数据集需要排除index列】
    """
    retDataSet=[]
    for line in DataSet:
        if line[index]==value:
            reducedline=line[:index]
            reducedline.extend(line[index+1:])
            retDataSet.append(reducedline)
    return retDataSet
    
#选择最好的数据集划分方式
def bestSplit(dataSet):
    """选择最好的特征,和最好的特征的最好的值

    参数：dataSet 数据集
    返回值：bestFeature 最优的特征列
    """
    numFeature=len(dataSet[0])-1
    baseEntropy=calcShannonEnt(dataSet)
    bestinfoGain,bestFeature=0.0,-1
    
    for i in range(numFeature):
        fealist=[fea[i] for fea in dataSet]
        uniquelist=set(fealist)
        newEntropy=0.0
        for value in uniquelist:
            subDataSet=splitDataSet(dataSet,i,value)
            prob=len(subDataSet)/float(len(dataSet))
            newEntropy+=prob*calcShannonEnt(subDataSet)#求和
        infoGain=baseEntropy-newEntropy
        print('信息增益为',infoGain,'特征为',i,baseEntropy,newEntropy)
        if(infoGain>bestinfoGain):
            bestinfoGain=infoGain
            bestFeature=i
        return bestFeature


#构造树的数据结构的训练算法-用字典构成树的数据结构
def createTree(dataSet,labels):
    classList=[line[-1] for line in dataSet]
    if len(classList)==classList.count(classList[0]):
        return classList[0]
    
    if len(dataSet)==1:
        return max(classList,key=classList.count)
    
    bestFeat=bestSplit(dataSet)
    featList=[example[bestFeat] for example in dataSet]
    featureList=set(featList)
    
    bestFeature=label[bestFeat]
    myTree={bestFeature:{}}
    
    del(labels[bestFeat])
    for value in featureList :
        sublabels=labels[:]
        myTree[bestFeature][value]=createTree(splitDataSet(dataSet,bestFeat,value),sublabels)
    return myTree





        
